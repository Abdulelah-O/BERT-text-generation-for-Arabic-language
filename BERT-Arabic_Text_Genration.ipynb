{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries\n",
    "- **glob** and **os**: To handle file operations.\n",
    "- **torch**: For tensor operations and managing model computations on GPU.\n",
    "- **Path**: From `pathlib` for easy file path manipulation.\n",
    "- **transformers**: Importing `AutoTokenizer` for tokenization, `BertForMaskedLM` for the BERT model, `Trainer` and `TrainingArguments` for setting up the training pipeline.\n",
    "- **datasets**: To handle dataset creation.\n",
    "- **DataCollatorForLanguageModeling**: To handle token masking for MLM (Masked Language Modeling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, BertForMaskedLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up device for computation\n",
    "- **Check for GPU availability**: The script sets the device to `cuda` if a GPU is available, otherwise it defaults to `cpu`.\n",
    "- **Disable Weights & Biases (WANDB) logging**: To prevent logging through WANDB during the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T02:27:46.784808Z",
     "iopub.status.busy": "2024-10-17T02:27:46.784187Z",
     "iopub.status.idle": "2024-10-17T02:27:46.797281Z",
     "shell.execute_reply": "2024-10-17T02:27:46.796236Z",
     "shell.execute_reply.started": "2024-10-17T02:27:46.784762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Disable WANDB logging\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T02:27:46.799484Z",
     "iopub.status.busy": "2024-10-17T02:27:46.799112Z",
     "iopub.status.idle": "2024-10-17T02:27:46.805961Z",
     "shell.execute_reply": "2024-10-17T02:27:46.805027Z",
     "shell.execute_reply.started": "2024-10-17T02:27:46.799442Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"culture\": 'nlp_dataset/articles-culture/*.txt',\n",
    "    \"economy\": 'nlp_dataset/articles-economy/*.txt',\n",
    "    \"international\": 'nlp_dataset/articles-international/*.txt',\n",
    "    \"local\": 'nlp_dataset/articles-local/*.txt',\n",
    "    \"religion\": 'nlp_dataset/articles-religion/*.txt',\n",
    "    \"sports\": 'nlp_dataset/articlesSports/*.txt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(paths.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading Functions\n",
    "- **`load_data(category)`**: Loads text files from a specific category using the provided file paths, reading and appending their content into a list.\n",
    "- **`load_all_data()`**: Iterates through all categories, loading data from each one and combining them into a single list.\n",
    "- **Load articles**: After calling `load_all_data()`, the total number of loaded articles is printed for verification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T02:27:46.807693Z",
     "iopub.status.busy": "2024-10-17T02:27:46.807109Z",
     "iopub.status.idle": "2024-10-17T02:28:15.017849Z",
     "shell.execute_reply": "2024-10-17T02:28:15.016916Z",
     "shell.execute_reply.started": "2024-10-17T02:27:46.807633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles loaded: 4095\n"
     ]
    }
   ],
   "source": [
    "# Function to load data from a specific category\n",
    "def load_data(category):\n",
    "    files = glob.glob(paths[category])\n",
    "    articles = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            articles.append(f.read())\n",
    "    return articles\n",
    "\n",
    "# Function to load data from all categories\n",
    "def load_all_data():\n",
    "    all_articles = []\n",
    "    for category in paths.keys():\n",
    "        all_articles.extend(load_data(category))\n",
    "    return all_articles\n",
    "\n",
    "# Load articles from all categories\n",
    "all_articles = load_all_data()\n",
    "print(f\"Total number of articles loaded: {len(all_articles)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization with AraBERT\n",
    "- **Initialize AraBERT tokenizer**: Uses the pre-trained tokenizer from \"aubmindlab/bert-base-arabertv02\" to handle Arabic text.\n",
    "- **`tokenize_articles(articles)`**: Tokenizes the input articles, applies padding to ensure uniform length, truncates articles longer than 512 tokens, and converts them to PyTorch tensors.\n",
    "- **Tokenize all articles**: The entire dataset is tokenized, and a confirmation message is printed once the process is complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T02:28:15.020864Z",
     "iopub.status.busy": "2024-10-17T02:28:15.020361Z",
     "iopub.status.idle": "2024-10-17T02:28:39.481303Z",
     "shell.execute_reply": "2024-10-17T02:28:39.480391Z",
     "shell.execute_reply.started": "2024-10-17T02:28:15.020818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All articles tokenized.\n"
     ]
    }
   ],
   "source": [
    "# Initialize AraBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv02\")\n",
    "\n",
    "# Function to tokenize articles\n",
    "def tokenize_articles(articles):\n",
    "    return tokenizer(articles, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize all articles\n",
    "tokenized_all_articles = tokenize_articles(all_articles)\n",
    "print(\"All articles tokenized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Evaluation Sets\n",
    "- **`split_dataset(tokenized_articles)`**: \n",
    "  - Splits the tokenized articles into **90% training** and **10% evaluation** sets.\n",
    "  - Separates both the `input_ids` and `attention_mask` for the training and evaluation datasets.\n",
    "- **Convert to Dataset objects**: \n",
    "  - `train_dataset` and `eval_dataset` are created from the split data for compatibility with the Hugging Face `Trainer`.\n",
    "- **Dataset size**: Prints the size of both the training and evaluation datasets to confirm the split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T02:28:39.482621Z",
     "iopub.status.busy": "2024-10-17T02:28:39.482331Z",
     "iopub.status.idle": "2024-10-17T02:28:41.669206Z",
     "shell.execute_reply": "2024-10-17T02:28:41.668275Z",
     "shell.execute_reply.started": "2024-10-17T02:28:39.482590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 3685\n",
      "Evaluation dataset size: 410\n"
     ]
    }
   ],
   "source": [
    "# Function to split the tokenized articles into train and eval sets\n",
    "def split_dataset(tokenized_articles):\n",
    "    train_size = int(0.9 * len(tokenized_articles['input_ids']))\n",
    "    train_dataset = {\n",
    "        \"input_ids\": tokenized_articles['input_ids'][:train_size],\n",
    "        \"attention_mask\": tokenized_articles['attention_mask'][:train_size],\n",
    "    }\n",
    "    eval_dataset = {\n",
    "        \"input_ids\": tokenized_articles['input_ids'][train_size:],\n",
    "        \"attention_mask\": tokenized_articles['attention_mask'][train_size:],\n",
    "    }\n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "# Split the data\n",
    "train_data, eval_data = split_dataset(tokenized_all_articles)\n",
    "\n",
    "# Convert data to Dataset objects\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "eval_dataset = Dataset.from_dict(eval_data)\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Evaluation dataset size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the AraBERT Model for Masked Language Modeling (MLM)\n",
    "- **BertForMaskedLM**: Loads the pre-trained AraBERT model (`bert-base-arabertv02`) specifically for Masked Language Modeling.\n",
    "- **Move model to GPU**: The model is transferred to GPU if available for faster training.\n",
    "\n",
    "### Data Collator for MLM\n",
    "- **DataCollatorForLanguageModeling**: Dynamically masks 15% of tokens (`mlm_probability=0.15`) during training, enabling the MLM objective where the model learns to predict the masked tokens.\n",
    "\n",
    "### Training Arguments\n",
    "- **`output_dir`**: Directory to store the results.\n",
    "- **Batch size**: Set to 8 per device (adjustable based on GPU capacity).\n",
    "- **Training epochs**: Set to 10 epochs.\n",
    "- **Save strategy**: Saves the model every 10,000 steps and limits to 2 checkpoints.\n",
    "- **Disable wandb logging**: Ensures that Weights & Biases logging is turned off.\n",
    "\n",
    "Model and training arguments are now ready for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T02:28:41.670665Z",
     "iopub.status.busy": "2024-10-17T02:28:41.670346Z",
     "iopub.status.idle": "2024-10-17T02:28:42.622236Z",
     "shell.execute_reply": "2024-10-17T02:28:42.621305Z",
     "shell.execute_reply.started": "2024-10-17T02:28:41.670632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02 were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForLanguageModeling(\n\u001b[0;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mlm_probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.15\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Define training arguments\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on GPU memory\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Disable wandb logging\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded and training arguments set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<string>:133\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, hub_revision, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, liger_kernel_config, eval_use_gather_object, average_tokens_across_devices)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1793\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[1;32m-> 1793\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m   1795\u001b[0m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_tokens_across_devices:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:2322\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2319\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   2320\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2321\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 2322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:76\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     74\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:2192\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   2191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 2192\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2193\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2195\u001b[0m         )\n\u001b[0;32m   2196\u001b[0m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m accelerator_state_kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_configured_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "# Load BERT model for masked language modeling\n",
    "model = BertForMaskedLM.from_pretrained(\"aubmindlab/bert-base-arabertv02\")\n",
    "model.to(device)  # Move model to GPU\n",
    "\n",
    "# Data collator for masked language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,  # Adjust based on GPU memory\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    report_to=[]  # Disable wandb logging\n",
    ")\n",
    "\n",
    "print(\"Model loaded and training arguments set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Trainer\n",
    "- **Trainer**: Initializes the Hugging Face `Trainer` with the following components:\n",
    "  - **model**: AraBERT model for Masked Language Modeling (MLM).\n",
    "  - **args**: Training arguments defined earlier (batch size, epochs, evaluation strategy, etc.).\n",
    "  - **data_collator**: Dynamically masks tokens during training for MLM.\n",
    "  - **train_dataset & eval_dataset**: The training and evaluation datasets previously split and tokenized.\n",
    "\n",
    "### Start Training\n",
    "- **trainer.train()**: Begins the training process for the model with the specified datasets and arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T02:28:42.623726Z",
     "iopub.status.busy": "2024-10-17T02:28:42.623389Z",
     "iopub.status.idle": "2024-10-17T06:29:21.391357Z",
     "shell.execute_reply": "2024-10-17T06:29:21.390417Z",
     "shell.execute_reply.started": "2024-10-17T02:28:42.623665Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10270' max='10270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10270/10270 4:00:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.843200</td>\n",
       "      <td>1.576623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.737400</td>\n",
       "      <td>1.542854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.670100</td>\n",
       "      <td>1.537364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.607600</td>\n",
       "      <td>1.517988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>1.511468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.502600</td>\n",
       "      <td>1.501382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.473600</td>\n",
       "      <td>1.484621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.437900</td>\n",
       "      <td>1.479608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.416600</td>\n",
       "      <td>1.471871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.416500</td>\n",
       "      <td>1.468602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10270, training_loss=1.5718477629872352, metrics={'train_runtime': 14438.1164, 'train_samples_per_second': 11.38, 'train_steps_per_second': 0.711, 'total_flos': 4.32614480805888e+16, 'train_loss': 1.5718477629872352, 'epoch': 10.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Trainer with both train and eval datasets\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:29:21.393184Z",
     "iopub.status.busy": "2024-10-17T06:29:21.392798Z",
     "iopub.status.idle": "2024-10-17T06:30:21.223077Z",
     "shell.execute_reply": "2024-10-17T06:30:21.222149Z",
     "shell.execute_reply.started": "2024-10-17T06:29:21.393140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='115' max='115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [115/115 00:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 1.4493675231933594, 'eval_runtime': 59.8225, 'eval_samples_per_second': 30.524, 'eval_steps_per_second': 1.922, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T06:30:21.225051Z",
     "iopub.status.busy": "2024-10-17T06:30:21.224398Z",
     "iopub.status.idle": "2024-10-17T06:30:22.607746Z",
     "shell.execute_reply": "2024-10-17T06:30:22.606798Z",
     "shell.execute_reply.started": "2024-10-17T06:30:21.225005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"./trained_model\")\n",
    "tokenizer.save_pretrained(\"./trained_model\")\n",
    "print(\"Model and tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model = BertForMaskedLM.from_pretrained(\"./trained_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./trained_model\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Masked Token Prediction and Text Completion\n",
    "- **`mask_and_complete_text()`**: This function iterates over an input text, predicting and replacing each `[MASK]` token using the AraBERT model.\n",
    "  - **Tokenization**: The input text is tokenized and sent to the model for prediction.\n",
    "  - **Predict masked tokens**: For each `[MASK]` token found, the model predicts the most likely token.\n",
    "  - **Iterative prediction**: The function continuously replaces the first `[MASK]` in the text with the predicted token and repeats until all masks are replaced.\n",
    "  - **GPU support**: Moves the inputs to GPU if available for faster computation.\n",
    "\n",
    "### Example usage\n",
    "- **Input**: The example sentence includes `[MASK]` tokens that the model will attempt to complete.\n",
    "- **Output**: The completed sentence is printed with the predicted tokens replacing the masks.\n",
    "\n",
    "In this example, AraBERT predicts the missing words in the sentence:  \n",
    "*\"عاصمة [MASK] هي الرياض وجدة تقع على البحر [MASK]\"*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:30:43.227925Z",
     "iopub.status.busy": "2024-10-17T07:30:43.227036Z",
     "iopub.status.idle": "2024-10-17T07:30:43.260114Z",
     "shell.execute_reply": "2024-10-17T07:30:43.259324Z",
     "shell.execute_reply.started": "2024-10-17T07:30:43.227884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Text: عاصمة [السعودية]  هي الرياض وجدة تقع على البحر [الأحمر]\n"
     ]
    }
   ],
   "source": [
    "def mask_and_complete_text(input_text, mask_token=\"[MASK]\"):\n",
    "    \"\"\"Uses AraBERT to predict missing tokens in Arabic text using masked language modeling.\"\"\"\n",
    "    \n",
    "    while mask_token in input_text:\n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        \n",
    "        # Move inputs to GPU if available\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        # Run the model to predict the masked tokens\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Get the predicted token ids for the [MASK] position\n",
    "        mask_token_index = torch.where(inputs['input_ids'] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "        # Check if there are still [MASK] tokens to predict\n",
    "        if len(mask_token_index) == 0:\n",
    "            break\n",
    "\n",
    "        # Get the prediction for the first [MASK] token found\n",
    "        predicted_token_id = outputs.logits[0, mask_token_index[0]].argmax(axis=-1)\n",
    "\n",
    "        # Decode the predicted token\n",
    "        predicted_token = tokenizer.decode(predicted_token_id)\n",
    "\n",
    "        # Replace the first [MASK] token with the predicted token in the original text\n",
    "        input_text = input_text.replace(mask_token, \"[\" + predicted_token +\"]\", 1)\n",
    "\n",
    "    return input_text\n",
    "\n",
    "# Example usage for text completion with Arabic input\n",
    "input_text = \"عاصمة [MASK]  هي الرياض وجدة تقع على البحر [MASK]\"\n",
    "completed_text = mask_and_complete_text(input_text)\n",
    "print(f\"Completed Text: {completed_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. الرياضة:\n",
    "\n",
    "الرياضة تعتبر جزءًا مهمًا من حياة الأفراد والمجتمعات. تساعد الرياضة في [MASK] اللياقة البدنية وتعزيز الصحة النفسية. في الآونة الأخيرة، أصبحت البطولات الرياضية الكبرى مثل [MASK] تحظى بمتابعة كبيرة على مستوى العالم.\n",
    "\n",
    "2. الأخبار المحلية في عمان:\n",
    "\n",
    "شهدت سلطنة عمان في الفترة الأخيرة تطورات ملحوظة في مجال البنية التحتية. المشاريع الجديدة تهدف إلى تحسين [MASK] وتعزيز الاقتصاد الوطني. بالإضافة إلى ذلك، يجري العمل على تطوير [MASK] السياحية لجذب المزيد من الزوار.\n",
    "\n",
    "3. الأخبار العالمية:\n",
    "\n",
    "تشهد الساحة العالمية تغيرات سريعة في العلاقات الدبلوماسية بين الدول. في الآونة الأخيرة، أعلنت [MASK] عن فرض عقوبات اقتصادية على [MASK]، مما أثار توترات سياسية كبيرة. بالإضافة إلى ذلك، تزايدت المخاوف بشأن استقرار [MASK] بسبب النزاعات المستمرة في المنطقة. من ناحية أخرى، تسعى [MASK] إلى تعزيز التعاون الدولي لمواجهة التحديات المشتركة مثل التغير المناخي.\n",
    "\n",
    "4. الثقافة العمانية:\n",
    "\n",
    "تعتبر الثقافة العمانية غنية بالتقاليد والفنون التي تمتد عبر قرون. تشتهر عمان بالفنون التقليدية مثل [MASK] والحرف اليدوية. كما تلعب الفعاليات الثقافية دورًا مهمًا في الحفاظ على [MASK] وتعريف الأجيال الجديدة بتاريخ البلاد.\n",
    "\n",
    "5. الدين الإسلامي:\n",
    "\n",
    "الدين الإسلامي يدعو إلى السلم والتعايش بين البشر. يؤكد الإسلام على أهمية [MASK] والتعاون بين أفراد المجتمع. كما يدعو إلى الالتزام بالأخلاق الحسنة مثل [MASK] والصدق في التعامل.\n",
    "\n",
    "6. الاقتصاد:\n",
    "\n",
    "الاقتصاد العالمي يشهد حاليًا تقلبات بسبب الأزمات المتلاحقة. في بعض الدول، تؤثر السياسات المالية على [MASK] المحلي بشكل مباشر. بينما تسعى الحكومات إلى تحقيق استقرار اقتصادي عبر تعزيز [MASK] وفتح أسواق جديدة."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unmasked text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:22:24.021538Z",
     "iopub.status.busy": "2024-10-17T07:22:24.021161Z",
     "iopub.status.idle": "2024-10-17T07:22:24.034363Z",
     "shell.execute_reply": "2024-10-17T07:22:24.033084Z",
     "shell.execute_reply.started": "2024-10-17T07:22:24.021502Z"
    }
   },
   "source": [
    "1. الرياضة:\n",
    "\n",
    "الرياضة تعتبر جزءًا مهمًا من حياة الأفراد والمجتمعات. تساعد الرياضة في تحسين اللياقة البدنية وتعزيز الصحة النفسية. في الآونة الأخيرة، أصبحت البطولات الرياضية الكبرى مثل كأس العالم تحظى بمتابعة كبيرة على مستوى العالم.\n",
    "\n",
    "2. الأخبار المحلية في عمان:\n",
    "\n",
    "شهدت سلطنة عمان في الفترة الأخيرة تطورات ملحوظة في مجال البنية التحتية. المشاريع الجديدة تهدف إلى تحسين الخدمات وتعزيز الاقتصاد الوطني. بالإضافة إلى ذلك، يجري العمل على تطوير المواقع السياحية لجذب المزيد من الزوار.\n",
    "\n",
    "3. الأخبار العالمية:\n",
    "\n",
    "في الأخبار العالمية، تتصدر التطورات السياسية والاقتصادية المشهد في العديد من الدول. الأزمة في أوكرانيا تؤثر بشكل مباشر على الأسواقتشهد الساحة العالمية تغيرات سريعة في العلاقات الدبلوماسية بين الدول. في الآونة الأخيرة، أعلنت الولايات المتحدة عن فرض عقوبات اقتصادية على روسيا، مما أثار توترات سياسية كبيرة. بالإضافة إلى ذلك، تزايدت المخاوف بشأن استقرار الشرق الأوسط بسبب النزاعات المستمرة في المنطقة. من ناحية أخرى، تسعى الاتحاد الأوروبي إلى تعزيز التعاون الدولي لمواجهة التحديات المشتركة مثل التغير المناخي\n",
    "\n",
    "4. الثقافة العمانية:\n",
    "\n",
    "تعتبر الثقافة العمانية غنية بالتقاليد والفنون التي تمتد عبر قرون. تشتهر عمان بالفنون التقليدية مثل الموسيقى الشعبية والحرف اليدوية. كما تلعب الفعاليات الثقافية دورًا مهمًا في الحفاظ على التراث وتعريف الأجيال الجديدة بتاريخ البلاد.\n",
    "\n",
    "5. الدين الإسلامي:\n",
    "\n",
    "الدين الإسلامي يدعو إلى السلم والتعايش بين البشر. يؤكد الإسلام على أهمية التعاون والتعاون بين أفراد المجتمع. كما يدعو إلى الالتزام بالأخلاق الحسنة مثل الأمانة والصدق في التعامل.\n",
    "\n",
    "6. الاقتصاد:\n",
    "\n",
    "الاقتصاد العالمي يشهد حاليًا تقلبات بسبب الأزمات المتلاحقة. في بعض الدول، تؤثر السياسات المالية على الناتج المحلي بشكل مباشر. بينما تسعى الحكومات إلى تحقيق استقرار اقتصادي عبر تعزيز الاستثمار وفتح أسواق جديدة."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:50:45.158650Z",
     "iopub.status.busy": "2024-10-17T07:50:45.157924Z",
     "iopub.status.idle": "2024-10-17T07:50:45.204091Z",
     "shell.execute_reply": "2024-10-17T07:50:45.203206Z",
     "shell.execute_reply.started": "2024-10-17T07:50:45.158611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Text:\n",
      "الرياضة تعتبر جزءًا مهمًا من حياة الأفراد والمجتمعات. تساعد الرياضة في [زيادة] اللياقة البدنية وتعزيز الصحة النفسية. في الآونة الأخيرة، أصبحت البطولات الرياضية الكبرى مثل [كرة] [القدم] تحظى بمتابعة كبيرة على مستوى العالم.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"الرياضة تعتبر جزءًا مهمًا من حياة الأفراد والمجتمعات. تساعد الرياضة في [MASK] اللياقة البدنية وتعزيز الصحة النفسية. في الآونة الأخيرة، أصبحت البطولات الرياضية الكبرى مثل [MASK] [MASK] تحظى بمتابعة كبيرة على مستوى العالم.\"\n",
    "completed_text = mask_and_complete_text(input_text)\n",
    "print(f\"Completed Text:\\n{completed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:30:59.388010Z",
     "iopub.status.busy": "2024-10-17T07:30:59.387281Z",
     "iopub.status.idle": "2024-10-17T07:30:59.421213Z",
     "shell.execute_reply": "2024-10-17T07:30:59.420180Z",
     "shell.execute_reply.started": "2024-10-17T07:30:59.387970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Text:\n",
      "شهدت سلطنة عمان في الفترة الأخيرة تطورات ملحوظة في مجال البنية التحتية. المشاريع الجديدة تهدف إلى تحسين [الخدمات] وتعزيز الاقتصاد الوطني. بالإضافة إلى ذلك، يجري العمل على تطوير [المرافق] السياحية لجذب المزيد من الزوار.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"شهدت سلطنة عمان في الفترة الأخيرة تطورات ملحوظة في مجال البنية التحتية. المشاريع الجديدة تهدف إلى تحسين [MASK] وتعزيز الاقتصاد الوطني. بالإضافة إلى ذلك، يجري العمل على تطوير [MASK] السياحية لجذب المزيد من الزوار.\"\n",
    "completed_text = mask_and_complete_text(input_text)\n",
    "print(f\"Completed Text:\\n{completed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:37:13.880218Z",
     "iopub.status.busy": "2024-10-17T07:37:13.879368Z",
     "iopub.status.idle": "2024-10-17T07:37:13.957547Z",
     "shell.execute_reply": "2024-10-17T07:37:13.956693Z",
     "shell.execute_reply.started": "2024-10-17T07:37:13.880175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Text:\n",
      "تشهد الساحة العالمية تغيرات سريعة في العلاقات الدبلوماسية بين الدول. في الآونة الأخيرة، أعلنت [واشنطن] عن فرض عقوبات اقتصادية على [إيران]، مما أثار توترات سياسية كبيرة. بالإضافة إلى ذلك، تزايدت المخاوف بشأن استقرار [العالم] بسبب النزاعات المستمرة في المنطقة. من ناحية أخرى، تسعى [الدول] إلى تعزيز التعاون الدولي لمواجهة التحديات المشتركة مثل التغير المناخي.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"تشهد الساحة العالمية تغيرات سريعة في العلاقات الدبلوماسية بين الدول. في الآونة الأخيرة، أعلنت [MASK] عن فرض عقوبات اقتصادية على [MASK]، مما أثار توترات سياسية كبيرة. بالإضافة إلى ذلك، تزايدت المخاوف بشأن استقرار [MASK] بسبب النزاعات المستمرة في المنطقة. من ناحية أخرى، تسعى [MASK] إلى تعزيز التعاون الدولي لمواجهة التحديات المشتركة مثل التغير المناخي.\"\n",
    "completed_text = mask_and_complete_text(input_text)\n",
    "print(f\"Completed Text:\\n{completed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:31:09.734837Z",
     "iopub.status.busy": "2024-10-17T07:31:09.733980Z",
     "iopub.status.idle": "2024-10-17T07:31:09.768229Z",
     "shell.execute_reply": "2024-10-17T07:31:09.767409Z",
     "shell.execute_reply.started": "2024-10-17T07:31:09.734799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Text:\n",
      "تعتبر الثقافة العمانية غنية بالتقاليد والفنون التي تمتد عبر قرون. تشتهر عمان بالفنون التقليدية مثل [الفنون] والحرف اليدوية. كما تلعب الفعاليات الثقافية دورًا مهمًا في الحفاظ على [التراث] وتعريف الأجيال الجديدة بتاريخ البلاد.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"تعتبر الثقافة العمانية غنية بالتقاليد والفنون التي تمتد عبر قرون. تشتهر عمان بالفنون التقليدية مثل [MASK] والحرف اليدوية. كما تلعب الفعاليات الثقافية دورًا مهمًا في الحفاظ على [MASK] وتعريف الأجيال الجديدة بتاريخ البلاد.\"\n",
    "completed_text = mask_and_complete_text(input_text)\n",
    "print(f\"Completed Text:\\n{completed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:32:25.104220Z",
     "iopub.status.busy": "2024-10-17T07:32:25.103477Z",
     "iopub.status.idle": "2024-10-17T07:32:25.136751Z",
     "shell.execute_reply": "2024-10-17T07:32:25.135924Z",
     "shell.execute_reply.started": "2024-10-17T07:32:25.104182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Text:\n",
      "الدين الإسلامي يدعو إلى السلم والتعايش بين البشر. يؤكد الإسلام على أهمية [التكافل] والتعاون بين أفراد المجتمع. كما يدعو إلى الالتزام بالأخلاق الحسنة مثل [الأمانة] والصدق في التعامل.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"الدين الإسلامي يدعو إلى السلم والتعايش بين البشر. يؤكد الإسلام على أهمية [MASK] والتعاون بين أفراد المجتمع. كما يدعو إلى الالتزام بالأخلاق الحسنة مثل [MASK] والصدق في التعامل.\"\n",
    "completed_text = mask_and_complete_text(input_text)\n",
    "print(f\"Completed Text:\\n{completed_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:33:48.674266Z",
     "iopub.status.busy": "2024-10-17T07:33:48.673893Z",
     "iopub.status.idle": "2024-10-17T07:33:48.708375Z",
     "shell.execute_reply": "2024-10-17T07:33:48.707446Z",
     "shell.execute_reply.started": "2024-10-17T07:33:48.674229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Text:\n",
      "الاقتصاد العالمي يشهد حاليًا تقلبات بسبب الأزمات المتلاحقة. في بعض الدول، تؤثر السياسات المالية على [الناتج] المحلي بشكل مباشر. بينما تسعى الحكومات إلى تحقيق استقرار اقتصادي عبر تعزيز [صادراتها] وفتح أسواق جديدة.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"الاقتصاد العالمي يشهد حاليًا تقلبات بسبب الأزمات المتلاحقة. في بعض الدول، تؤثر السياسات المالية على [MASK] المحلي بشكل مباشر. بينما تسعى الحكومات إلى تحقيق استقرار اقتصادي عبر تعزيز [MASK] وفتح أسواق جديدة.\"\n",
    "completed_text = mask_and_complete_text(input_text)\n",
    "print(f\"Completed Text:\\n{completed_text}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5889800,
     "sourceId": 9644420,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
